{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ldy/anaconda3/envs/BCI/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import argparse\n",
    "import warnings\n",
    "\n",
    "# 设置环境变量\n",
    "os.environ[\"WANDB_API_KEY\"] = \"KEY\"\n",
    "os.environ[\"WANDB_MODE\"] = 'offline'\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "\n",
    "# 获取当前工作目录（假设 Notebook 位于 parent_dir）\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# 构建项目根目录的路径（假设 parent_dir 和 model 同级）\n",
    "project_root = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "\n",
    "# 将项目根目录添加到 sys.path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# 现在可以使用绝对导入\n",
    "from model.unified_encoder_multi_tower import UnifiedEncoder\n",
    "\n",
    "# 导入必要的库\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import wandb\n",
    "wandb.init(mode=\"disabled\")\n",
    "\n",
    "from data_preparing.eegdatasets import EEGDataset\n",
    "from data_preparing.megdatasets_averaged import MEGDataset\n",
    "from data_preparing.fmri_datasets_joint_subjects import fMRIDataset\n",
    "from data_preparing.datasets_mixer import MetaEEGDataset, MetaMEGDataset, MetafMRIDataset, MetaDataLoader\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from loss import ClipLoss\n",
    "from model.diffusion_prior import Pipe, EmbeddingDataset, DiffusionPriorUNet\n",
    "from model.custom_pipeline import Generator4Embeds\n",
    "# 忽略警告\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "proxy = 'http://10.20.37.38:7890'\n",
    "os.environ['http_proxy'] = proxy\n",
    "os.environ['https_proxy'] = proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Modality: eeg\n",
      "Test Subjects: ['sub-01']\n",
      "Number of Test Classes: 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_id_from_string(s):\n",
    "    match = re.search(r'\\d+$', s)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    return None\n",
    "\n",
    "def get_eegfeatures(unified_model, dataloader, device, text_features_all, img_features_all, k, eval_modality, test_classes):\n",
    "    unified_model.eval()\n",
    "    text_features_all = text_features_all[eval_modality].to(device).float()\n",
    "    if eval_modality=='eeg' or eval_modality=='fmri':\n",
    "        img_features_all = (img_features_all[eval_modality]).to(device).float()\n",
    "    elif eval_modality=='meg':\n",
    "        img_features_all = (img_features_all[eval_modality][::12]).to(device).float()  \n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    top5_correct_count=0\n",
    "    total = 0\n",
    "    loss_func = ClipLoss() \n",
    "    all_labels = set(range(text_features_all.size(0)))\n",
    "    save_features = False\n",
    "    features_list = []  # List to store features    \n",
    "    features_tensor = torch.zeros(0, 0)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (modal, data, labels, text, text_features, img, img_features, _, _, sub_ids) in enumerate(dataloader):\n",
    "            data = data.to(device)\n",
    "            text_features = text_features.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "            img_features = img_features.to(device).float()\n",
    "            \n",
    "            batch_size = data.size(0) \n",
    "            subject_ids = [extract_id_from_string(sub_id) for sub_id in sub_ids]\n",
    "            subject_ids = torch.tensor(subject_ids, dtype=torch.long).to(device)\n",
    "            neural_features = unified_model(data, subject_ids, modal=eval_modality)\n",
    "            \n",
    "            logit_scale = unified_model.logit_scale.float()            \n",
    "            features_list.append(neural_features)\n",
    "               \n",
    "            img_loss = loss_func(neural_features, img_features, logit_scale)\n",
    "            loss = img_loss        \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            for idx, label in enumerate(labels):\n",
    "\n",
    "                possible_classes = list(all_labels - {label.item()})\n",
    "                selected_classes = random.sample(possible_classes, k-1) + [label.item()]\n",
    "                selected_img_features = img_features_all[selected_classes]\n",
    "                \n",
    "\n",
    "                logits_img = logit_scale * neural_features[idx] @ selected_img_features.T\n",
    "                # logits_text = logit_scale * neural_features[idx] @ selected_text_features.T\n",
    "                # logits_single = (logits_text + logits_img) / 2.0\n",
    "                logits_single = logits_img\n",
    "                # print(\"logits_single\", logits_single.shape)\n",
    "\n",
    "                # predicted_label = selected_classes[torch.argmax(logits_single).item()]\n",
    "                predicted_label = selected_classes[torch.argmax(logits_single).item()] # (n_batch, ) \\in {0, 1, ..., n_cls-1}\n",
    "                if predicted_label == label.item():\n",
    "                    correct += 1        \n",
    "                if k==test_classes:\n",
    "                    _, top5_indices = torch.topk(logits_single, 5, largest =True)\n",
    "                                                            \n",
    "                    # Check if the ground truth label is among the top-5 predictions\n",
    "                    if label.item() in [selected_classes[i] for i in top5_indices.tolist()]:                \n",
    "                        top5_correct_count+=1                                 \n",
    "                total += 1              \n",
    "        \n",
    "    average_loss = total_loss / (batch_idx+1)\n",
    "    accuracy = correct / total    \n",
    "    top5_acc = top5_correct_count / total    \n",
    "    return average_loss, accuracy, top5_acc, labels, features_tensor.cpu()\n",
    "\n",
    "\n",
    "\n",
    "# Define Parameters\n",
    "encoder_paths_list = [\n",
    "    'eeg=/mnt/dataset1/ldy/Workspace/EEG_Image_decode/Retrieval/models/contrast/across/ATMS/01-06_01-46/150.pth',\n",
    "    'meg=/mnt/dataset1/ldy/Workspace/EEG_Image_decode/Retrieval/models/contrast/across/ATMS/01-11_14-50/150.pth',\n",
    "    'fmri=/mnt/dataset0/ldy/Workspace/EEG_Image_decode/Retrieval/models/contrast/across/ATMS/01-18_01-35/50.pth'\n",
    "]\n",
    "eval_modality = 'eeg'  # Modality to evaluate on\n",
    "\n",
    "# Subjects Configuration\n",
    "test_subjects = ['sub-02', 'sub-03', 'sub-04', 'sub-05', 'sub-06', 'sub-07', 'sub-08', 'sub-09', 'sub-10']\n",
    "# test_subjects = ['sub-01']\n",
    "eeg_subjects = ['sub-01', 'sub-02', 'sub-03', 'sub-04', 'sub-05', 'sub-06', 'sub-07', 'sub-08', 'sub-09', 'sub-10']\n",
    "meg_subjects = ['sub-01', 'sub-02', 'sub-03', 'sub-04']\n",
    "fmri_subjects = ['sub-01', 'sub-02', 'sub-03']\n",
    "\n",
    "modalities = ['eeg', 'meg', 'fmri']  # Modalities to include in inference\n",
    "test_classes = 100\n",
    "# Update test_subjects and test_classes based on eval_modality\n",
    "# if eval_modality == 'eeg':\n",
    "#     test_subjects = eeg_subjects\n",
    "#     test_classes = 200\n",
    "# elif eval_modality == 'meg':\n",
    "#     test_subjects = meg_subjects\n",
    "#     test_classes = 200\n",
    "# elif eval_modality == 'fmri':\n",
    "#     test_subjects = fmri_subjects\n",
    "#     test_classes = 100\n",
    "# else:\n",
    "#     raise ValueError(f\"Unsupported modality: {eval_modality}\")\n",
    "\n",
    "# Example usage\n",
    "print(f\"Evaluation Modality: {eval_modality}\")\n",
    "print(f\"Test Subjects: {test_subjects}\")\n",
    "print(f\"Number of Test Classes: {test_classes}\")\n",
    "\n",
    "# Dataset Paths\n",
    "# eeg_data_path = \"/home/ldy/4090_Workspace/4090_THINGS/Preprocessed_data_250Hz\"\n",
    "# meg_data_path = \"/home/ldy/THINGS-MEG/preprocessed_newsplit\"\n",
    "# fmri_data_path = \"/home/ldy/fmri_dataset/Preprocessed\"\n",
    "\n",
    "# parser.add_argument('--eeg_data_path', type=str, default=\"/mnt/dataset0/ldy/datasets/THINGS_EEG/Preprocessed_data_250Hz\", help='Path to the EEG dataset')\n",
    "# parser.add_argument('--meg_data_path', type=str, default=\"/mnt/dataset0/ldy/datasets/THINGS_MEG/preprocessed_newsplit\", help='Path to the MEG dataset')    \n",
    "# parser.add_argument('--fmri_data_path', type=str, default=\"/mnt/dataset0/ldy/datasets/fmri_dataset/Preprocessed\", help='Path to the fMRI dataset')     \n",
    "\n",
    "eeg_data_path = \"/mnt/dataset0/ldy/datasets/THINGS_EEG/Preprocessed_data_250Hz\"\n",
    "meg_data_path = \"/mnt/dataset0/ldy/datasets/THINGS_MEG/preprocessed_newsplit\"\n",
    "fmri_data_path = \"/mnt/dataset0/ldy/datasets/fmri_dataset/Preprocessed\"\n",
    "\n",
    "# Output and Logging Configuration (Not needed for inference, but kept for completeness)\n",
    "output_dir = './outputs/contrast'\n",
    "project = \"train_pos_img_text_rep\"\n",
    "entity = \"sustech_rethinkingbci\"\n",
    "name = \"lr=3e-4_img_pos_pro_eeg\"\n",
    "\n",
    "# Inference Parameters\n",
    "device_preference = 'cuda'  # e.g., 'cuda:0' or 'cpu'\n",
    "device_type = 'gpu'  # 'cpu' or 'gpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Total parameters: 161.96M\n",
      "Trainable parameters: 7.36M\n",
      "Trainable parameters percentage: 4.54%\n",
      "self.subjects ['sub-01']\n",
      "adap_subject None\n",
      "Data tensor shape: torch.Size([200, 63, 250]), label tensor shape: torch.Size([200]), text length: 200, image length: 200\n",
      " - Test Loss: 0.0000, Test Accuracy: 0.3250, Top5 Accuracy: 0.6100\n",
      " - Test Loss: 0.0000, v2_acc Accuracy: 0.9400\n",
      " - Test Loss: 0.0000, v4_acc Accuracy: 0.8200\n",
      " - Test Loss: 0.0000, v10_acc Accuracy: 0.6450\n",
      "\n",
      "Average Test Accuracy across all subjects: 0.3250\n",
      "\n",
      "Average Test Top5 Accuracy across all subjects: 0.6100\n",
      "Average v2_acc Accuracy across all subjects: 0.9400\n",
      "Average v4_acc Accuracy across all subjects: 0.8200\n",
      "Average v10_acc Accuracy across all subjects: 0.6450\n"
     ]
    }
   ],
   "source": [
    "# Process encoder_paths into a dictionary\n",
    "encoder_paths = {}\n",
    "for path in encoder_paths_list:\n",
    "    key, value = path.split('=')\n",
    "    encoder_paths[key] = value\n",
    "\n",
    "# Set device based on the argument\n",
    "device = torch.device(device_preference if device_type == 'gpu' and torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize empty datasets for each modality\n",
    "text_features_test_all = {}\n",
    "img_features_test_all = {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "# Initialize the Unified Encoder Model\n",
    "unified_model = UnifiedEncoder(encoder_paths, device, user_caption=False)\n",
    "# unified_model.load_state_dict(torch.load(\"/mnt/dataset1/ldy/Workspace/FLORA/models/contrast/across/Unified_EEG+MEG+fMRI_EEG/01-26_14-01/150.pth\"))\n",
    "# unified_model.load_state_dict(torch.load(\"/mnt/dataset1/ldy/Workspace/FLORA/models/contrast/across/Unified_EEG+MEG+fMRI_EEG/01-27_14-29/300.pth\"))\n",
    "unified_model.load_state_dict(torch.load(\"/mnt/dataset1/ldy/Workspace/FLORA/models/contrast/across/Unified_EEG+MEG+fMRI_EEG/01-29_01-18/300.pth\"))\n",
    "# unified_model.load_state_dict(torch.load(\"/mnt/dataset1/ldy/Workspace/FLORA/models/contrast/across/Unified_EEG+MEG+fMRI_EEG/01-29_10-25/300.pth\"))\n",
    "unified_model.to(device)\n",
    "unified_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# diffusion_prior = DiffusionPriorUNet(cond_dim=1024, dropout=0.1)\n",
    "# high_pipe = Pipe(diffusion_prior, device=device)\n",
    "# high_pipe.diffusion_prior.load_state_dict(torch.load(\"/mnt/dataset0/ldy/models/contrast/across/Unified_EEG+MEG+fMRI_EEG/01-22_18-16/prior_diffusion/60.pth\"))\n",
    "# high_pipe.diffusion_prior.to(device)\n",
    "# high_pipe.diffusion_prior.eval()  # Set model to evaluation mode\n",
    "\n",
    "\n",
    "# Print model parameters info\n",
    "def format_num(num):\n",
    "    for unit in ['','K','M','B','T']:\n",
    "        if num < 1000:\n",
    "            return f\"{num:.2f}{unit}\"\n",
    "        num /= 1000\n",
    "    return f\"{num:.2f}P\"\n",
    "\n",
    "total_params = sum(p.numel() for p in unified_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in unified_model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {format_num(total_params)}\")\n",
    "print(f\"Trainable parameters: {format_num(trainable_params)}\")\n",
    "\n",
    "if total_params > 0:\n",
    "    trainable_percentage = (trainable_params / total_params) * 100\n",
    "    print(f\"Trainable parameters percentage: {trainable_percentage:.2f}%\")\n",
    "else:\n",
    "    print(\"Total parameters count is zero, cannot compute percentage.\")\n",
    "#####################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "import numpy as np  # 导入numpy用于计算平均值\n",
    "test_accuracies = []\n",
    "test_accuracies_top5 = []\n",
    "v2_accuracies = []\n",
    "v4_accuracies = []\n",
    "v10_accuracies = []\n",
    "\n",
    "for sub in test_subjects:\n",
    "    # Prepare test dataset based on eval_modality and test_subjects\n",
    "    if eval_modality == 'eeg':\n",
    "        test_dataset = EEGDataset(eeg_data_path, subjects=[sub], train=False)\n",
    "    elif eval_modality == 'meg':\n",
    "        test_dataset = MEGDataset(meg_data_path, subjects=[sub], train=False)\n",
    "    elif eval_modality == 'fmri':\n",
    "        test_dataset = fMRIDataset(fmri_data_path, adap_subject=sub, subjects=[sub], train=False)\n",
    "    \n",
    "    # Collect test features\n",
    "    text_features_test_all[eval_modality] = test_dataset.text_features\n",
    "    img_features_test_all[eval_modality] = test_dataset.img_features\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0, drop_last=False)\n",
    "    test_loss, test_accuracy, top5_acc, labels, eeg_features_test = get_eegfeatures(\n",
    "        unified_model, test_loader, device, text_features_test_all, img_features_test_all, k=test_classes, eval_modality=eval_modality, test_classes=test_classes\n",
    "    )\n",
    "    _, v2_acc, _, _, _ = get_eegfeatures(\n",
    "        unified_model, test_loader, device, text_features_test_all, img_features_test_all, k=2, eval_modality=eval_modality, test_classes=test_classes\n",
    "    )\n",
    "    _, v4_acc, _, _, _ = get_eegfeatures(\n",
    "        unified_model, test_loader, device, text_features_test_all, img_features_test_all, k=4, eval_modality=eval_modality, test_classes=test_classes\n",
    "    )\n",
    "    _, v10_acc, _, _, _ = get_eegfeatures(\n",
    "        unified_model, test_loader, device, text_features_test_all, img_features_test_all, k=10, eval_modality=eval_modality, test_classes=test_classes\n",
    "    )    \n",
    "    \n",
    "    test_accuracies.append(test_accuracy)\n",
    "    test_accuracies_top5.append(top5_acc)\n",
    "    v2_accuracies.append(v2_acc)\n",
    "    v4_accuracies.append(v4_acc)\n",
    "    v10_accuracies.append(v10_acc)\n",
    "    \n",
    "    print(f\" - Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, Top5 Accuracy: {top5_acc:.4f}\")    \n",
    "    print(f\" - Test Loss: {test_loss:.4f}, v2_acc Accuracy: {v2_acc:.4f}\")\n",
    "    print(f\" - Test Loss: {test_loss:.4f}, v4_acc Accuracy: {v4_acc:.4f}\")\n",
    "    print(f\" - Test Loss: {test_loss:.4f}, v10_acc Accuracy: {v10_acc:.4f}\")\n",
    "\n",
    "# 计算各项指标的平均准确率\n",
    "average_test_accuracy = np.mean(test_accuracies)\n",
    "average_test_accuracy_top5 = np.mean(test_accuracies_top5)\n",
    "average_v2_acc = np.mean(v2_accuracies)\n",
    "average_v4_acc = np.mean(v4_accuracies)\n",
    "average_v10_acc = np.mean(v10_accuracies)\n",
    "\n",
    "print(f\"\\nAverage Test Accuracy across all subjects: {average_test_accuracy:.4f}\")\n",
    "print(f\"\\nAverage Test Top5 Accuracy across all subjects: {average_test_accuracy_top5:.4f}\")\n",
    "print(f\"Average v2_acc Accuracy across all subjects: {average_v2_acc:.4f}\")\n",
    "print(f\"Average v4_acc Accuracy across all subjects: {average_v4_acc:.4f}\")\n",
    "print(f\"Average v10_acc Accuracy across all subjects: {average_v10_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.68it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "diffusion_prior = DiffusionPriorUNet(cond_dim=1024, dropout=0.1)\n",
    "high_pipe = Pipe(diffusion_prior, device=device)\n",
    "# high_pipe.diffusion_prior.load_state_dict(torch.load(\"/mnt/dataset1/ldy/Workspace/FLORA/models/contrast/across/Unified_EEG+MEG+fMRI_EEG/01-26_14-01/prior_diffusion/150.pth\"))\n",
    "# high_pipe.diffusion_prior.load_state_dict(torch.load(\"/mnt/dataset1/ldy/Workspace/FLORA/models/contrast/across/Unified_EEG+MEG+fMRI_EEG/01-27_14-29/prior_diffusion/300.pth\"))\n",
    "high_pipe.diffusion_prior.load_state_dict(torch.load(\"/mnt/dataset1/ldy/Workspace/FLORA/models/contrast/across/Unified_EEG+MEG+fMRI_EEG/01-29_01-18/prior_diffusion/300.pth\"))\n",
    "# high_pipe.diffusion_prior.load_state_dict(torch.load(\"/mnt/dataset1/ldy/Workspace/FLORA/models/contrast/across/Unified_EEG+MEG+fMRI_EEG/01-29_10-25/prior_diffusion/300.pth\"))\n",
    "high_pipe.diffusion_prior.to(device)\n",
    "high_pipe.diffusion_prior.eval()  # Set model to evaluation mode\n",
    "\n",
    "# set a seed value\n",
    "seed_value = 42\n",
    "generator = Generator4Embeds(num_inference_steps=4, device=device)\n",
    "gen = torch.Generator(device=device)\n",
    "gen.manual_seed(seed_value)\n",
    "folder = f'./{eval_modality}_generated_imgs'\n",
    "os.makedirs(folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.subjects ['sub-01']\n",
      "adap_subject None\n",
      "Data tensor shape: torch.Size([200, 63, 250]), label tensor shape: torch.Size([200]), text length: 200, image length: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 142.47it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  8.39it/s]\n",
      "10it [00:00, 191.94it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.28it/s]\n",
      "10it [00:00, 193.29it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.93it/s]\n",
      "10it [00:00, 194.54it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.12it/s]\n",
      "10it [00:00, 193.63it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.16it/s]\n",
      "10it [00:00, 186.37it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.15it/s]\n",
      "10it [00:00, 189.52it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.01it/s]\n",
      "10it [00:00, 188.72it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.77it/s]\n",
      "10it [00:00, 186.80it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.69it/s]\n",
      "10it [00:00, 185.91it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.68it/s]\n",
      "10it [00:00, 186.49it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.73it/s]\n",
      "10it [00:00, 194.03it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.82it/s]\n",
      "10it [00:00, 189.19it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.87it/s]\n",
      "10it [00:00, 184.00it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.12it/s]\n",
      "10it [00:00, 193.73it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.98it/s]\n",
      "10it [00:00, 185.51it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.01it/s]\n",
      "10it [00:00, 194.70it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.19it/s]\n",
      "10it [00:00, 189.30it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.95it/s]\n",
      "10it [00:00, 191.44it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.12it/s]\n",
      "10it [00:00, 194.84it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.19it/s]\n",
      "10it [00:00, 202.99it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.09it/s]\n",
      "10it [00:00, 191.49it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.02it/s]\n",
      "10it [00:00, 195.64it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.14it/s]\n",
      "10it [00:00, 194.30it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.99it/s]\n",
      "10it [00:00, 194.25it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.98it/s]\n",
      "10it [00:00, 185.69it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.92it/s]\n",
      "10it [00:00, 191.78it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.78it/s]\n",
      "10it [00:00, 184.70it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.76it/s]\n",
      "10it [00:00, 184.92it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.08it/s]\n",
      "10it [00:00, 192.44it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.79it/s]\n",
      "10it [00:00, 192.91it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.01it/s]\n",
      "10it [00:00, 187.86it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.83it/s]\n",
      "10it [00:00, 186.03it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.74it/s]\n",
      "10it [00:00, 190.19it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.87it/s]\n",
      "10it [00:00, 189.26it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.88it/s]\n",
      "10it [00:00, 189.16it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.83it/s]\n",
      "10it [00:00, 189.20it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.84it/s]\n",
      "10it [00:00, 190.92it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.92it/s]\n",
      "10it [00:00, 196.06it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.82it/s]\n",
      "10it [00:00, 187.76it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.74it/s]\n",
      "10it [00:00, 187.44it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.81it/s]\n",
      "10it [00:00, 193.54it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.91it/s]\n",
      "10it [00:00, 188.61it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.00it/s]\n",
      "10it [00:00, 189.28it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.88it/s]\n",
      "10it [00:00, 190.55it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.85it/s]\n",
      "10it [00:00, 204.47it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.01it/s]\n",
      "10it [00:00, 192.06it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.90it/s]\n",
      "10it [00:00, 185.12it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.79it/s]\n",
      "10it [00:00, 190.19it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.86it/s]\n",
      "10it [00:00, 187.92it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.88it/s]\n",
      "10it [00:00, 185.90it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.01it/s]\n",
      "10it [00:00, 191.48it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.31it/s]\n",
      "10it [00:00, 195.70it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.02it/s]\n",
      "10it [00:00, 195.67it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.07it/s]\n",
      "10it [00:00, 188.01it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.97it/s]\n",
      "10it [00:00, 195.84it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.90it/s]\n",
      "10it [00:00, 192.23it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.86it/s]\n",
      "10it [00:00, 200.01it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.13it/s]\n",
      "10it [00:00, 206.82it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.84it/s]\n",
      "10it [00:00, 194.81it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.33it/s]\n",
      "10it [00:00, 195.19it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.18it/s]\n",
      "10it [00:00, 192.02it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.12it/s]\n",
      "10it [00:00, 194.26it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.50it/s]\n",
      "10it [00:00, 188.06it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.80it/s]\n",
      "10it [00:00, 192.26it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.00it/s]\n",
      "10it [00:00, 190.81it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.28it/s]\n",
      "10it [00:00, 193.98it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.04it/s]\n",
      "10it [00:00, 198.15it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.97it/s]\n",
      "10it [00:00, 206.63it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.27it/s]\n",
      "10it [00:00, 191.53it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.72it/s]\n",
      "10it [00:00, 190.00it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.05it/s]\n",
      "10it [00:00, 193.41it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.96it/s]\n",
      "10it [00:00, 199.82it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.43it/s]\n",
      "10it [00:00, 186.93it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.25it/s]\n",
      "10it [00:00, 199.33it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.74it/s]\n",
      "10it [00:00, 201.74it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.12it/s]\n",
      "10it [00:00, 192.11it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.85it/s]\n",
      "10it [00:00, 188.67it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.00it/s]\n",
      "10it [00:00, 186.97it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.15it/s]\n",
      "10it [00:00, 188.59it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.16it/s]\n",
      "10it [00:00, 188.06it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.20it/s]\n",
      "10it [00:00, 194.53it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.15it/s]\n",
      "10it [00:00, 186.03it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.21it/s]\n",
      "10it [00:00, 188.00it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.89it/s]\n",
      "10it [00:00, 190.72it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.91it/s]\n",
      "10it [00:00, 186.92it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.67it/s]\n",
      "10it [00:00, 199.73it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.20it/s]\n",
      "10it [00:00, 196.42it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.07it/s]\n",
      "10it [00:00, 193.58it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.05it/s]\n",
      "10it [00:00, 199.41it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.05it/s]\n",
      "10it [00:00, 194.98it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.12it/s]\n",
      "10it [00:00, 189.99it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.98it/s]\n",
      "10it [00:00, 192.00it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.23it/s]\n",
      "10it [00:00, 186.84it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.11it/s]\n",
      "10it [00:00, 196.62it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.60it/s]\n",
      "10it [00:00, 196.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.58it/s]\n",
      "10it [00:00, 197.25it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.08it/s]\n",
      "10it [00:00, 188.19it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.73it/s]\n",
      "10it [00:00, 200.63it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.97it/s]\n",
      "10it [00:00, 195.52it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.96it/s]\n",
      "10it [00:00, 195.44it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.03it/s]\n",
      "10it [00:00, 185.22it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.96it/s]\n",
      "10it [00:00, 193.10it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.67it/s]\n",
      "10it [00:00, 190.26it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.94it/s]\n",
      "10it [00:00, 193.29it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.03it/s]\n",
      "10it [00:00, 194.35it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.08it/s]\n",
      "10it [00:00, 190.86it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.94it/s]\n",
      "10it [00:00, 189.01it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.79it/s]\n",
      "10it [00:00, 188.79it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.86it/s]\n",
      "10it [00:00, 199.22it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.80it/s]\n",
      "10it [00:00, 189.02it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.92it/s]\n",
      "10it [00:00, 194.21it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.99it/s]\n",
      "10it [00:00, 189.02it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.01it/s]\n",
      "10it [00:00, 203.66it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.93it/s]\n",
      "10it [00:00, 193.36it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.79it/s]\n",
      "10it [00:00, 198.48it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.02it/s]\n",
      "10it [00:00, 190.16it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.94it/s]\n",
      "10it [00:00, 193.14it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.73it/s]\n",
      "10it [00:00, 159.72it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.86it/s]\n",
      "10it [00:00, 192.27it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.31it/s]\n",
      "10it [00:00, 186.51it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.74it/s]\n",
      "10it [00:00, 188.26it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.66it/s]\n",
      "10it [00:00, 187.48it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.94it/s]\n",
      "10it [00:00, 191.53it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.75it/s]\n",
      "10it [00:00, 189.36it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.64it/s]\n",
      "10it [00:00, 193.06it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.49it/s]\n",
      "10it [00:00, 171.56it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.78it/s]\n",
      "10it [00:00, 174.26it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.64it/s]\n",
      "10it [00:00, 182.70it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.73it/s]\n",
      "10it [00:00, 186.88it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.89it/s]\n",
      "10it [00:00, 202.01it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.51it/s]\n",
      "10it [00:00, 203.83it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.77it/s]\n",
      "10it [00:00, 192.62it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.03it/s]\n",
      "10it [00:00, 193.67it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.93it/s]\n",
      "10it [00:00, 197.76it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.95it/s]\n",
      "10it [00:00, 192.56it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.91it/s]\n",
      "10it [00:00, 195.96it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.26it/s]\n",
      "10it [00:00, 167.77it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.32it/s]\n",
      "10it [00:00, 181.95it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.57it/s]\n",
      "10it [00:00, 190.84it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.77it/s]\n",
      "10it [00:00, 199.23it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.40it/s]\n",
      "10it [00:00, 192.43it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.08it/s]\n",
      "10it [00:00, 203.06it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.61it/s]\n",
      "10it [00:00, 190.97it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.05it/s]\n",
      "10it [00:00, 201.86it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.15it/s]\n",
      "10it [00:00, 173.14it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.91it/s]\n",
      "10it [00:00, 192.84it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.86it/s]\n",
      "10it [00:00, 195.68it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.15it/s]\n",
      "10it [00:00, 186.45it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.89it/s]\n",
      "10it [00:00, 194.01it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.15it/s]\n",
      "10it [00:00, 200.01it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.11it/s]\n",
      "10it [00:00, 191.24it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.07it/s]\n",
      "10it [00:00, 195.22it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.12it/s]\n",
      "10it [00:00, 198.89it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.26it/s]\n",
      "10it [00:00, 195.32it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.09it/s]\n",
      "10it [00:00, 196.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.84it/s]\n",
      "10it [00:00, 192.23it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.19it/s]\n",
      "10it [00:00, 190.44it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.11it/s]\n",
      "10it [00:00, 203.61it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.06it/s]\n",
      "10it [00:00, 192.82it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.11it/s]\n",
      "10it [00:00, 194.49it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.81it/s]\n",
      "10it [00:00, 189.91it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.98it/s]\n",
      "10it [00:00, 199.30it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.06it/s]\n",
      "10it [00:00, 196.28it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.18it/s]\n",
      "10it [00:00, 196.48it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.00it/s]\n",
      "10it [00:00, 195.10it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.70it/s]\n",
      "10it [00:00, 198.14it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.59it/s]\n",
      "10it [00:00, 200.12it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.20it/s]\n",
      "10it [00:00, 204.29it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.23it/s]\n",
      "10it [00:00, 190.93it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.06it/s]\n",
      "10it [00:00, 193.52it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.00it/s]\n",
      "10it [00:00, 192.28it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.09it/s]\n",
      "10it [00:00, 194.52it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.07it/s]\n",
      "10it [00:00, 198.21it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.08it/s]\n",
      "10it [00:00, 201.27it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.04it/s]\n",
      "10it [00:00, 202.57it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.03it/s]\n",
      "10it [00:00, 204.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.15it/s]\n",
      "10it [00:00, 195.89it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.00it/s]\n",
      "10it [00:00, 194.07it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.08it/s]\n",
      "10it [00:00, 191.21it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.07it/s]\n",
      "10it [00:00, 193.44it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.07it/s]\n",
      "10it [00:00, 195.49it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.03it/s]\n",
      "10it [00:00, 192.63it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.01it/s]\n",
      "10it [00:00, 187.54it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.88it/s]\n",
      "10it [00:00, 185.42it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.83it/s]\n",
      "10it [00:00, 188.98it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.81it/s]\n",
      "10it [00:00, 184.30it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.84it/s]\n",
      "10it [00:00, 192.25it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.69it/s]\n",
      "10it [00:00, 193.76it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.84it/s]\n",
      "10it [00:00, 207.81it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.91it/s]\n",
      "10it [00:00, 202.01it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.26it/s]\n",
      "10it [00:00, 190.71it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.01it/s]\n",
      "10it [00:00, 188.32it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.00it/s]\n",
      "10it [00:00, 190.28it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.84it/s]\n",
      "10it [00:00, 193.85it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.42it/s]\n",
      "10it [00:00, 187.93it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.81it/s]\n",
      "10it [00:00, 194.12it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.98it/s]\n",
      "10it [00:00, 186.67it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.89it/s]\n",
      "10it [00:00, 191.34it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.63it/s]\n",
      "10it [00:00, 190.10it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.86it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_priorfeatures(unified_model, dataloader, device, text_features_all, img_features_all, k, eval_modality, test_classes):\n",
    "    unified_model.eval()\n",
    "    text_features_all = text_features_all[eval_modality].to(device).float()\n",
    "    if eval_modality=='eeg' or eval_modality=='fmri':\n",
    "        img_features_all = (img_features_all[eval_modality]).to(device).float()\n",
    "    elif eval_modality=='meg':\n",
    "        img_features_all = (img_features_all[eval_modality][::12]).to(device).float()  \n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    top5_correct_count=0\n",
    "    total = 0\n",
    "    loss_func = ClipLoss() \n",
    "    all_labels = set(range(text_features_all.size(0)))\n",
    "    save_features = False\n",
    "    features_list = []  # List to store features    \n",
    "    features_tensor = torch.zeros(0, 0)\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (modal, data, labels, text, text_features, img, img_features, _, _, sub_ids) in enumerate(dataloader):\n",
    "            data = data.to(device)\n",
    "            text_features = text_features.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "            img_features = img_features.to(device).float()\n",
    "            \n",
    "            batch_size = data.size(0) \n",
    "            subject_ids = [extract_id_from_string(sub_id) for sub_id in sub_ids]\n",
    "            subject_ids = torch.tensor(subject_ids, dtype=torch.long).to(device)\n",
    "            neural_features = unified_model(data, subject_ids, modal=eval_modality)\n",
    "            # print(\"neural_features\", neural_features.shape)\n",
    "            for i in range(neural_features.shape[0]):\n",
    "                h = high_pipe.generate(c_embeds=neural_features[i].unsqueeze(0), num_inference_steps=10, guidance_scale=2.0)\n",
    "\n",
    "                # image_1 = generator.generate(eeg_embeds_1[index], generator=gen)  \n",
    "                # display(image_1)\n",
    "\n",
    "                image_2 = generator.generate(h, generator=gen)  \n",
    "                # display(image_2)          \n",
    "                # 设置保存图像的路径和文件名\n",
    "                file_path = os.path.join(folder, f'image_{count+1}.png')  # 图像名称为 image_1.png, image_2.png, 等等                \n",
    "                # 保存图像\n",
    "                image_2.save(file_path)  # 使用 PIL 或图像对象的 .save 方法保存图像  \n",
    "                count+=1\n",
    "            logit_scale = unified_model.logit_scale.float()            \n",
    "            features_list.append(neural_features)\n",
    "               \n",
    "            img_loss = loss_func(neural_features, img_features, logit_scale)\n",
    "            loss = img_loss        \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            for idx, label in enumerate(labels):\n",
    "\n",
    "                possible_classes = list(all_labels - {label.item()})\n",
    "                selected_classes = random.sample(possible_classes, k-1) + [label.item()]\n",
    "                selected_img_features = img_features_all[selected_classes]\n",
    "                \n",
    "\n",
    "                logits_img = logit_scale * neural_features[idx] @ selected_img_features.T\n",
    "                # logits_text = logit_scale * neural_features[idx] @ selected_text_features.T\n",
    "                # logits_single = (logits_text + logits_img) / 2.0\n",
    "                logits_single = logits_img\n",
    "                # print(\"logits_single\", logits_single.shape)\n",
    "\n",
    "                # predicted_label = selected_classes[torch.argmax(logits_single).item()]\n",
    "                predicted_label = selected_classes[torch.argmax(logits_single).item()] # (n_batch, ) \\in {0, 1, ..., n_cls-1}\n",
    "                if predicted_label == label.item():\n",
    "                    correct += 1        \n",
    "                if k==test_classes:\n",
    "                    _, top5_indices = torch.topk(logits_single, 5, largest =True)\n",
    "                                                            \n",
    "                    # Check if the ground truth label is among the top-5 predictions\n",
    "                    if label.item() in [selected_classes[i] for i in top5_indices.tolist()]:                \n",
    "                        top5_correct_count+=1                                 \n",
    "                total += 1              \n",
    "\n",
    "        if save_features:\n",
    "            features_tensor = torch.cat(features_list, dim=0)\n",
    "            print(\"features_tensor\", features_tensor.shape)\n",
    "            torch.save(features_tensor.cpu(), f\"neural_features_eval_{eval_modality}_{sub}_test.pt\")  # Save features as .pt file\n",
    "    average_loss = total_loss / (batch_idx+1)\n",
    "    accuracy = correct / total    \n",
    "    top5_acc = top5_correct_count / total    \n",
    "    return average_loss, accuracy, top5_acc, labels, features_tensor.cpu()\n",
    "\n",
    "\n",
    "for sub in test_subjects:\n",
    "    # Prepare test dataset based on eval_modality and test_subjects\n",
    "    if eval_modality == 'eeg':\n",
    "        test_dataset = EEGDataset(eeg_data_path, subjects=[sub], train=False)\n",
    "    elif eval_modality == 'meg':\n",
    "        test_dataset = MEGDataset(meg_data_path, subjects=[sub], train=False)\n",
    "    elif eval_modality == 'fmri':\n",
    "        test_dataset = fMRIDataset(fmri_data_path, adap_subject=sub, subjects=[sub], train=False)\n",
    "    \n",
    "    # Collect test features\n",
    "    text_features_test_all[eval_modality] = test_dataset.text_features\n",
    "    img_features_test_all[eval_modality] = test_dataset.img_features\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0, drop_last=False)\n",
    "    test_loss, test_accuracy, top5_acc, labels, eeg_features_test = get_priorfeatures(\n",
    "        unified_model, test_loader, device, text_features_test_all, img_features_test_all, k=test_classes, eval_modality=eval_modality, test_classes=test_classes\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BCI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
